{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pos_tagger_assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahLid8zZW5km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlHtU-oSc7aE",
        "colab_type": "code",
        "outputId": "39995232-4579-4933-fd43-b0184c49f459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpfzJNqShKxm",
        "colab_type": "code",
        "outputId": "c76b56b9-1463-4c29-b7f1-3c504fc72851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "% pip install pomegranate\n",
        "#Pomegranate is a graphical models library for Python, implemented in Cython for speed"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pomegranate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/8a/51bb4268722c26f67738a0da8ab43df49bbb01016a135b6aa1c45bd33670/pomegranate-0.13.3.tar.gz (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.9.0b4 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (0.15.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (2.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from pomegranate) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from pomegranate) (3.13)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->pomegranate) (4.4.2)\n",
            "Building wheels for collected packages: pomegranate\n",
            "  Building wheel for pomegranate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pomegranate: filename=pomegranate-0.13.3-cp36-cp36m-linux_x86_64.whl size=10950002 sha256=d05b25ec82387428f0bdfd38cb40e7df8c32f37dbb81c2cac39a88ce686bc74c\n",
            "  Stored in directory: /root/.cache/pip/wheels/92/a4/39/0f9e71a9134d03801477bffa6e02257020f12e5cbb031a8489\n",
            "Successfully built pomegranate\n",
            "Installing collected packages: pomegranate\n",
            "Successfully installed pomegranate-0.13.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlWFWn6FiMio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks/assignment\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkmiEtoWizEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.core.display import HTML\n",
        "from itertools import chain\n",
        "from collections import Counter,defaultdict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rymcx5XX6Pcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from helpers import show_model, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yRTtNMA6MlC",
        "colab_type": "code",
        "outputId": "697c42a3-edd9-4631-ab8d-327b073135da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "data = Dataset(\"/content/drive/My Drive/Colab Notebooks/assignment/tags-universal.txt\", \"/content/drive/My Drive/Colab Notebooks/assignment/brown-universal.txt\", train_test_split=0.8)\n",
        "\n",
        "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
        "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
        "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
        "\n",
        "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
        "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 57340 sentences in the corpus.\n",
            "There are 45872 sentences in the training set.\n",
            "There are 11468 sentences in the testing set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PWud9OEqH_V",
        "colab_type": "code",
        "outputId": "c94e964d-4963-4cfb-c275-78cb9c76ca81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "key = 'b100-38532'\n",
        "print(\"Sentence: {}\".format(key))\n",
        "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
        "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence: b100-38532\n",
            "words:\n",
            "\t('Perhaps', 'it', 'was', 'right', ';', ';')\n",
            "tags:\n",
            "\t('ADV', 'PRON', 'VERB', 'ADJ', '.', '.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fqf5t72oqTEk",
        "colab_type": "code",
        "outputId": "c4fe3a34-4800-48a8-c2d6-ce48b7798c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
        "      .format(data.N, len(data.vocab)))\n",
        "print(\"There are {} samples of {} unique words in the training set.\"\n",
        "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
        "print(\"There are {} samples of {} unique words in the testing set.\"\n",
        "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
        "print(\"There are {} words in the test set that are missing in the training set.\"\n",
        "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
        "\n",
        "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
        "       \"The number of training + test samples should sum to the total number of samples\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
            "There are 928458 samples of 50536 unique words in the training set.\n",
            "There are 232734 samples of 25112 unique words in the testing set.\n",
            "There are 5521 words in the test set that are missing in the training set.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smt33C45qp9h",
        "colab_type": "code",
        "outputId": "94f0b0f2-5b5e-473b-8d0a-9bd045e92d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "source": [
        "# accessing words with Dataset.X and tags with Dataset.Y \n",
        "for i in range(5):    \n",
        "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
        "    print()\n",
        "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
        "    print()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
            "\n",
            "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
            "\n",
            "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
            "\n",
            "Sentence 3: ('Such', 'an', 'instrument', 'is', 'expected', 'to', 'be', 'especially', 'useful', 'if', 'it', 'could', 'be', 'used', 'to', 'measure', 'the', 'elasticity', 'of', 'heavy', 'pastes', 'such', 'as', 'printing', 'inks', ',', 'paints', ',', 'adhesives', ',', 'molten', 'plastics', ',', 'and', 'bread', 'dough', ',', 'for', 'the', 'elasticity', 'is', 'related', 'to', 'those', 'various', 'properties', 'termed', '``', 'length', \"''\", ',', '``', 'shortness', \"''\", ',', '``', 'spinnability', \"''\", ',', 'etc.', ',', 'which', 'are', 'usually', 'judged', 'by', 'subjective', 'methods', 'at', 'present', '.')\n",
            "\n",
            "Labels 3: ('PRT', 'DET', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADJ', 'ADP', 'PRON', 'VERB', 'VERB', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADJ', 'ADP', 'VERB', 'NOUN', '.', 'NOUN', '.', 'NOUN', '.', 'ADJ', 'NOUN', '.', 'CONJ', 'NOUN', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', '.', 'NOUN', '.', '.', '.', 'NOUN', '.', '.', '.', 'NOUN', '.', '.', 'ADV', '.', 'DET', 'VERB', 'ADV', 'VERB', 'ADP', 'ADJ', 'NOUN', 'ADP', 'NOUN', '.')\n",
            "\n",
            "Sentence 4: ('My', 'future', 'plans', 'are', 'to', 'become', 'a', 'language', 'teacher', '.')\n",
            "\n",
            "Labels 4: ('DET', 'ADJ', 'NOUN', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'NOUN', '.')\n",
            "\n",
            "Sentence 5: ('We', 'ran', 'east', 'for', 'about', 'half', 'a', 'mile', 'before', 'we', 'turned', 'back', 'to', 'the', 'road', ',', 'panting', 'from', 'the', 'effort', 'and', 'soaked', 'with', 'sweat', '.')\n",
            "\n",
            "Labels 5: ('PRON', 'VERB', 'NOUN', 'ADP', 'ADV', 'PRT', 'DET', 'NOUN', 'ADP', 'PRON', 'VERB', 'ADV', 'ADP', 'DET', 'NOUN', '.', 'VERB', 'ADP', 'DET', 'NOUN', 'CONJ', 'VERB', 'ADP', 'NOUN', '.')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pd719Acquke",
        "colab_type": "code",
        "outputId": "a553c444-3d64-4f0c-f06b-bb8f8fc2dd70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "# use Dataset.stream() (word, tag) samples for the entire corpus\n",
        "print(\"\\nStream (word, tag) pairs:\\n\")\n",
        "for i, pair in enumerate(data.stream()):\n",
        "    print(\"\\t\", pair)\n",
        "    if i > 10: break"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stream (word, tag) pairs:\n",
            "\n",
            "\t ('Mr.', 'NOUN')\n",
            "\t ('Podger', 'NOUN')\n",
            "\t ('had', 'VERB')\n",
            "\t ('thanked', 'VERB')\n",
            "\t ('him', 'PRON')\n",
            "\t ('gravely', 'ADV')\n",
            "\t (',', '.')\n",
            "\t ('and', 'CONJ')\n",
            "\t ('now', 'ADV')\n",
            "\t ('he', 'PRON')\n",
            "\t ('made', 'VERB')\n",
            "\t ('use', 'NOUN')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D44Wj-4mtamg",
        "colab_type": "code",
        "outputId": "b62dcbd1-d357-42b7-dbb0-d17f03f73c7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from collections import Counter,defaultdict\n",
        "\n",
        "def pair_counts(tags,words):\n",
        "\td=defaultdict(lambda: defaultdict(int))\n",
        "\tfor tag,word in zip(tags,words):\n",
        "\t\td[tag][word]+=1\n",
        "\treturn d\n",
        "\traise NotImplementedError\n",
        "tags = [tag for i,(word, tag) in enumerate(data.training_set.stream())]\n",
        "words = [word for i,(word, tag) in enumerate(data.training_set.stream())]\n",
        "\n",
        "emission_counts =pair_counts(tags,words)\n",
        "\n",
        "tags"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ADV',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'PRT',\n",
              " 'ADP',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'NUM',\n",
              " '.',\n",
              " 'NUM',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADV',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NUM',\n",
              " '.',\n",
              " 'NUM',\n",
              " '.',\n",
              " 'PRT',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'CONJ',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADJ',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'ADV',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'ADV',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'CONJ',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " '.',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " '.',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'PRT',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'PRT',\n",
              " 'NUM',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'NUM',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADP',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'ADV',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'PRON',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'PRON',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADV',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADV',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NUM',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'NUM',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'NUM',\n",
              " 'ADP',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADV',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " '.',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'NUM',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADV',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'CONJ',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'ADJ',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'VERB',\n",
              " 'NOUN',\n",
              " 'CONJ',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " 'PRT',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NUM',\n",
              " 'NUM',\n",
              " '.',\n",
              " '.',\n",
              " 'PRON',\n",
              " 'VERB',\n",
              " 'PRON',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADV',\n",
              " '.',\n",
              " '.',\n",
              " 'CONJ',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'DET',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'CONJ',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " '.',\n",
              " 'PRT',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'PRT',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'ADJ',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'NOUN',\n",
              " 'NOUN',\n",
              " '.',\n",
              " 'NOUN',\n",
              " '.',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcwmg-Vtt-uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
        "from collections import namedtuple\n",
        "\n",
        "FakeState = namedtuple(\"FakeState\", \"name\")\n",
        "\n",
        "class MFCTagger:\n",
        "    # NOTE: You should not need to modify this class or any of its methods\n",
        "    missing = FakeState(name=\"<MISSING>\")\n",
        "    \n",
        "    def __init__(self, table):\n",
        "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
        "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
        "        \n",
        "    def viterbi(self, seq):\n",
        "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
        "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
        "\n",
        "\n",
        "# TODO: calculate the frequency of each tag being assigned to each word (hint: similar, but not\n",
        "# the same as the emission probabilities) and use it to fill the mfc_table\n",
        "\n",
        "tags = [tag for i, (word, tag) in enumerate(data.training_set.stream())]\n",
        "words = [word for i, (word, tag) in enumerate(data.training_set.stream())]\n",
        "#Since this is the word_counts we will pass first words and then counts\n",
        "word_counts = pair_counts(words,tags)\n",
        "\n",
        "mfc_table = dict((word, max(tags.keys(), key=lambda key: tags[key])) for word, tags in word_counts.items())\n",
        "\n",
        "# DO NOT MODIFY BELOW THIS LINE\n",
        "mfc_model = MFCTagger(mfc_table) # Create a Most Frequent Class tagger instance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkdFAyV4wEAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_unknown(sequence):\n",
        "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
        "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
        "    during computation.\n",
        "    \"\"\"\n",
        "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
        "\n",
        "def simplify_decoding(X, model):\n",
        "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
        "    _, state_path = model.viterbi(replace_unknown(X))\n",
        "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lppovC3vwU74",
        "colab_type": "code",
        "outputId": "746f82fb-6b64-4ac0-a4c9-40c79a7e3f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for key in data.testing_set.keys[:5]:\n",
        "    print(\"Sentence Key: {}\\n\".format(key))\n",
        "    print(\"Predicted labels:\\n-----------------\")\n",
        "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
        "    print()\n",
        "    print(\"Actual labels:\\n--------------\")\n",
        "    print(data.sentences[key].tags)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence Key: b100-28144\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-23146\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-35462\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', '<MISSING>', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADV', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-37008\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-18135\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', '<MISSING>', 'VERB', 'VERB', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'VERB', 'VERB', '.')\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoRqyZmPw866",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(X, Y, model):\n",
        " \n",
        "    correct = total_predictions = 0\n",
        "    for observations, actual_tags in zip(X, Y):\n",
        "        \n",
        "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
        "        # raises an error (for example, if a test sentence contains a word that\n",
        "        # is out of vocabulary for the training set). Any exception counts the\n",
        "        # full sentence as an error (which makes this a conservative estimate).\n",
        "        try:\n",
        "            most_likely_tags = simplify_decoding(observations, model)\n",
        "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
        "        except:\n",
        "            pass\n",
        "        total_predictions += len(observations)\n",
        "    return correct / total_predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7A7iqWmxlMp",
        "colab_type": "code",
        "outputId": "480870b6-3e4a-493c-caf8-8335d53eac8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
        "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
        "\n",
        "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
        "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy mfc_model: 95.72%\n",
            "testing accuracy mfc_model: 93.01%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pdsi7gxDqNF3",
        "colab_type": "text"
      },
      "source": [
        "IMPLEMENTATION of Unigram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvFCHgiGqMTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unigram_counts(sequences):\n",
        "    return Counter(sequences)\n",
        "    raise NotImplementedError\n",
        "tag_unigrams = unigram_counts(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUMH1GWuqeQj",
        "colab_type": "text"
      },
      "source": [
        "IMPLEMENTATION of Bigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYnAnZnjqjlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bigram_counts(sequences):\n",
        "    return Counter(zip(sequences, sequences[1:]))\n",
        "    raise NotImplementedError\n",
        "\n",
        "tag_bigrams = bigram_counts(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g__0aF4hrEvH",
        "colab_type": "text"
      },
      "source": [
        "IMPLEMENTATION of Sequence Starting Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pwh3uRQ6rHou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def starting_counts(sequences):\n",
        "    return Counter([x[0] for x in sequences])\n",
        "    raise NotImplementedError\n",
        "tag_starts = starting_counts(data.training_set.Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBECCmUcrTrr",
        "colab_type": "text"
      },
      "source": [
        "IMPLEMENTATION of Sequence Ending Counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJuuDtUJrS-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ending_counts(sequences):\n",
        "    return Counter([x[-1] for x in sequences])\n",
        "    raise NotImplementedError\n",
        "\n",
        "tag_ends = ending_counts(data.training_set.Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njUmW1dyo8Wf",
        "colab_type": "text"
      },
      "source": [
        "IMPLEMENTATION of HMM Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWOr1YGapcYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5eBY78oadS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d1e0htipUBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_counts = pair_counts(tags, words)\n",
        "tag_state = {}\n",
        "for tag in data.training_set.tagset:\n",
        "    for word in data.training_set.vocab:\n",
        "        try:\n",
        "            tag_counts[tag][word] /= tag_unigrams[tag]\n",
        "        except:\n",
        "            tag_counts[tag][word] = 0\n",
        "    emission = DiscreteDistribution(dict(tag_counts[tag]))\n",
        "    tag_state[tag] = State(emission, name=tag)\n",
        "basic_model.add_states(list(tag_state.values()))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLi_AW-6rzfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag_transition = defaultdict(lambda:0)\n",
        "for tag in tag_unigrams.keys():\n",
        "    for tag2 in tag_unigrams.keys():\n",
        "        basic_model.add_transition(tag_state[tag], tag_state[tag2],\n",
        "                                   tag_bigrams[(tag,tag2)] / tag_unigrams[tag])\n",
        "    basic_model.add_transition(basic_model.start, tag_state[tag],\n",
        "                              tag_starts[tag] / len(data.training_set))\n",
        "    basic_model.add_transition(tag_state[tag], basic_model.end,\n",
        "                              tag_ends[tag] / tag_unigrams[tag])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AEkXBxEpkto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "basic_model.bake()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSrtL5xMpnVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "aecba2e7-8a12-451a-ce39-a8333f7c5606"
      },
      "source": [
        "observations = ['what', 'is', 'it']\n",
        "forward_matrix = np.exp(basic_model.forward(observations))\n",
        "probability_percentage = np.exp(basic_model.log_probability(observations))\n",
        "print(\"        \" + \"\".join(s.name.center(len(s.name)+6) for s in basic_model.states))\n",
        "for i in range(len(observations) + 1):\n",
        "    print(\" <start> \" if i==0 else observations[i - 1].center(9), end=\"\")\n",
        "    print(\"\".join(\"{:.4f}%\".format(100 * forward_matrix[i, j]).center(len(s.name) + 6)\n",
        "                  for j, s in enumerate(basic_model.states)))\n",
        "\n",
        "print(\"\\nThe likelihood over all possible paths \" + \\\n",
        "      \"of this model producing the sequence {} is {:.10f}%\\n\\n\"\n",
        "      .format(observations, 100 * probability_percentage))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           .      ADJ      ADP      ADV      CONJ      DET      NOUN      NUM      PRON      PRT      VERB      X      base-hmm-tagger-start      base-hmm-tagger-end   \n",
            " <start> 0.0000% 0.0000%  0.0000%  0.0000%  0.0000%   0.0000%  0.0000%   0.0000%  0.0000%   0.0000%  0.0000%  0.0000%         100.0000%                  0.0000%         \n",
            "   what  0.0000% 0.0000%  0.0000%  0.0000%  0.0000%   0.2197%  0.0000%   0.0000%  0.0000%   0.0000%  0.0000%  0.0000%          0.0000%                   0.0000%         \n",
            "    is   0.0000% 0.0000%  0.0000%  0.0000%  0.0000%   0.0000%  0.0000%   0.0000%  0.0000%   0.0000%  0.0008%  0.0000%          0.0000%                   0.0000%         \n",
            "    it   0.0000% 0.0000%  0.0000%  0.0000%  0.0000%   0.0000%  0.0000%   0.0000%  0.0000%   0.0000%  0.0000%  0.0000%          0.0000%                   0.0000%         \n",
            "\n",
            "The likelihood over all possible paths of this model producing the sequence ['what', 'is', 'it'] is 0.0000000006%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mFN5YCdsQSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "outputId": "c8d7410f-b244-4142-e741-9d01932838b7"
      },
      "source": [
        "for key in data.testing_set.keys[:3]:\n",
        "    print(\"Sentence Key: {}\\n\".format(key))\n",
        "    print(\"Predicted labels:\\n-----------------\")\n",
        "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
        "    print()\n",
        "    print(\"Actual labels:\\n--------------\")\n",
        "    print(data.sentences[key].tags)\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence Key: b100-28144\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-23146\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
            "\n",
            "\n",
            "Sentence Key: b100-35462\n",
            "\n",
            "Predicted labels:\n",
            "-----------------\n",
            "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n",
            "\n",
            "Actual labels:\n",
            "--------------\n",
            "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biN-PWEbsHSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "2cd79866-21c0-4257-f345-2b82bfc6c0ff"
      },
      "source": [
        "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
        "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
        "\n",
        "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
        "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training accuracy basic hmm model: 97.52%\n",
            "testing accuracy basic hmm model: 95.94%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}